[{"content":"The Messaging Layer Security (MLS) protocol is an IETF proposal for group key establishment and message protection. OpenMLS is a Rust implementation of the MLS protocol in its current state (draft 11 as of the point of writing this) that is being implemented by Raphael, Konrad and myself. For more general information on MLS I refer to the spec and other blog posts. This blog post is only about MLS, and in particular OpenMLS, performance.\nOne goal of MLS is that it is supposed to be scalable. The charter in particular claims the following:\n Resource requirements have good scaling in the size of the group (preferably sub-linear)\n While performance can be theoretically analysed for MLS it is also interesting to see whether the performance goals hold up in a real implementation. This of course only looks at a single implementation. Nonetheless, I think that it gives a good impression on the actual performance of MLS implementations. Particularly because OpenMLS at this point is not optimised but rather implements the MLS spec as is.\nMethodology MLS is a pretty complex protocol with many moving parts. It is therefore important to clearly define what is being measured and how.\nFirst, all tests are done with the only mandatory cipher suite in MLS 1.0 MLS10_128_DHKEMX25519_AES128GCM_SHA256_Ed25519. While other cipher suites obviously have different performance, the goal here is to investigate the general performance of MLS depending on the group size. The exact cipher suite used is therefore irrelevant.\nMeasurements The measurements here do not cover all possible messages in MLS. Not all of them are fully supported by OpenMLS yet. Pre-shared key, re-init, external-init, app-ack, and external proposals will be checked once they are implemented. The measured messages nonetheless represent the core of the MLS protocol and should give a good idea of the general performance of the protocol. We test performance of group creation, group join as well as the three basic messages update, add, and remove, and application messages.\nAll measurements except for the first two use one of the following set-ups:\n  Base: The group is created by a user. All other participants are invited and each participant creates the group locally. Then every participant sends an update message to the group and everyone else processes it.\n  Bare: The group is created by a user. All other participants are invited and each participant creates the group locally. This creates an extremely sparse version of the underlying tree in MLS and is therefore interesting to look at.\n  Measurements are run on different group sizes. When running benchmarks with large groups such as 1000 participants a lot of memory is used in order to simulate all devices (up to 10 GB) such that larger groups are hard to simulate. The chosen group sizes allow us to get a good idea how MLS performs depending on the group size. We in particular test groups of the size 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000.\nOperations  Group creation: Creating a group involves creating the group, proposals and welcome messages for the other participants, and applying the commit. Join group: Joining a group is equivalent to processing a welcome message to locally create the new group. Update messages: Sending an update to a group involves creating a proposal, the corresponding commit and applying the commit. When receiving an update message the commit is being processed. Adding a user: When a new user is added to the group the add proposal and welcome message are created and the commit is locally applied by the adder. When receiving a commit with an add proposal it is processed by the user. Removing a user: When a user is removed from the group the remove proposal and commit are created and locally applied by the remover. When receiving a commit with a remove proposal it is processed by the user. Application messages: Sending an application message consists of creating the plaintext message and encrypting it for the group. In order to receive an application message the user has to decrypt and parse the message. We measure performance of a single message that is being sent and processed. Note that the processing time of subsequent messages is not significantly different from the first one.  Results You can find the raw data and some more graphs in the OpenMLS performance spreadsheet.\nAll measurements were performed on a laptop with Arch Linux, an Intel Core i7-4900MQ @ 2.80GHz and 16 GB memory.\nGroup setup As the following graph shows the time needed to create a group is linear in the number of participants added when creating the group. The blue line shows the actual measurements while the magenta one is a trend line showing the linear relation. This is what is to be expected because the performance is dominated by the creation of welcome messages, which have to be created for each member.\n \nJoin group The performance of joining a group is linear in the group size because the information in the welcome message as well as the tree that is being processed when joining the group are linear in the number of group members. Note that it is not logarithmic because the tree needs to be constructed. This requires processing of each node in some way, which is linear in the group size. The blue line again shows the actual measurements while the magenta one is a trend line for the linear relation.\n \nUpdate Sending and processing updates are both sub-linear in the number of group members because the number of computations depend on the height of the tree in the base case.\n \nIn the case of a very sparse tree, which we have in the bare case because every leaf only processed the welcome message, the performance of sending an update however is linear in the group size. When creating a commit for an update proposal the sender has to include a path and refresh the private tree. The following two flamegraphs show the difference between the base and the bare case. While it doesn\u0026rsquo;t show directly what\u0026rsquo;s going on, it can be seen that in the base case (first flamegraph) the new_with_keys function requires a lot more time relative to the rest of the replace_private_tree function. This is a strong indicator for where to look for the differences.\n \n \nLooking at a tree with 300 leaves for example we have to encrypt 299 times (for every other leaf) in the case of a bare tree. In a fully updated tree however only 9 encryptions are necessary, one for each level of the tree. It is therefore expected that the performance of sending an update (with commit) in the bare case is linear in the group size.\nAdding a user Looking at the performance of adding a user and processing an add commit in the following graph we can again see the linear growth in relation to the number of group members. This is almost independent of the state of the tree. The operations appear to be slightly more expensive in a fully updated tree though.\n \nRemoving a user Like updating, removing a user and processing a remove commit are linear in complexity in the base case as the following graph shows. Removing in a very sparse tree is significantly more expensive than in a fully updated tree. The reason is the same as for updating the tree. The remove information has to be encrypted to all other remaining participants in the tree.\n \nApplication messages Sending and receiving application messages is essentially independent of the group size, as expected. Receiving the first message within an epoch has a small overhead compared to subsequent message as seen in the second graph. This should be negligible in practice though.\n \n \nAnalysis First, the plain performance numbers tell us that the goal of the MLS charter of a protocol that scales well for large groups has been mostly. Depending on the state of the tree some operations might take longer than expected. However, this can be mitigated by the application ensuring that the tree is updated and shrunk regularly. Notably, the real world performance appears to be consistent with the theoretical expectations.\nTechnical background The measurements are not done with any Rust benchmarking framework such as criterion. Due to the way criterion works there\u0026rsquo;s significant overhead in criterion. While the numbers in this post can be reliably reproduced a more thorough measurement framework\nThe flamegraphs are produced with pprof, a simple to use CPU profiler for Rust.\nAll measurements were performed on this revision. To reproduce them check out the revision and run\nfor i in 2 3 4 5 6 7 8 9 10 20 30 40 50 100 200 300 400 500 1000; do \\  cargo bench --bench group -- $i; \\ done Conclusion \u0026amp; Future work Measuring performance of a protocol as complex as MLS is pretty difficult. Without an application and elaborate test framework that can simulate many different scenarios it is only possible to get the basic numbers as shown here. While they give a good indicator towards the performance of the MLS protocol they are insufficient to claim any performance of real applications that use MLS.\nNonetheless, the numbers show that the MLS protocol appears to allow for efficient, end-to-end-encrypted messaging in large groups. Sending and receiving application messages is independent of the group size while group operations are sub-linear in the group size in most cases.\nWhen OpenMLS is further developed and we have a messaging client using it another set of measurements should be performed with real world usage scenarios in mind in order to investigate whether the performance we have seen here translates to efficient group messaging in an application. The MLS specification further leaves anything around authentication and authorization policies open to the application. These might be complex procedures and impact the MLS performance as well.\n","date":"2021-05-18T00:00:00Z","image":"https://www.franziskuskiefer.de/p/openmls-performance/openmls-logo.svg","permalink":"https://www.franziskuskiefer.de/p/openmls-performance/","title":"OpenMLS Performance"},{"content":"Thanks to Deez I gave web monetization a spin on this website today. Here I write up how I did it, how it went, and what I think about it.\nThe proposed web monetization standard allows browsers to securely pay websites, and, in turn, allows for websites to react to being paid, for example by turning off ads or providing extra functionality to paying visitors. There is some good description of use cases on Coil\u0026rsquo;s website if you\u0026rsquo;re looking for a more general explainer.\nThe following diagram from the web monetization docs illustrate the information flow. In short, the monetization meta-tag on the page is parsed by the browser, which initiates a session for a page visit and triggers the payment through the payment pointer.\n \nPayment pointer üì¨ To set up web monetization on a website like this, one first has to get a payment pointer that can receive payments. Getting this payment pointer was probably the hardest part for me.\nI selected one of the recommended wallet providers Uphold. Uphold has a support page for how to get the ILP (Interledger payment pointer). The problem is that it\u0026rsquo;s difficult to understand how to get to the \u0026ldquo;sub-account for the asset\u0026rdquo;. In fact I was only able to do this in Brave because uphold.com/dashboard always forwards me to wallet.uphold.com/dashboard, which doesn\u0026rsquo;t have the necessary information (or I just didn\u0026rsquo;t find it).\nSetting all trust concerns aside (see the privacy section) I tried to verify my Uphold account. The verification didn\u0026rsquo;t go through yet ü§î. But I can still receive funds and have honestly no idea what\u0026rsquo;s happening here. This is a pretty bad sign for a provider that\u0026rsquo;s supposed to handle money for me.\n \nThe Interledger üìí The Interledger is an open protocol suite for sending payments across different ledgers. It is used by the web monetization framework to send the money to the website owner or content creator. You might know that I have opinions on cryptocurrencies and blockchain technologies (hint: they are not very positive). I understand that there aren\u0026rsquo;t a lot of good ways of sending money to individuals or organisations that supports a lot of different technologies and currencies. But I don\u0026rsquo;t understand why any sort of ledger needs to be involved.\nPrivacy \u0026amp; Security considerations üîêüïµüèª‚Äç‚ôÄÔ∏è The first road block I hit was the registration of the uphold account. It looks like it requires registration with a government ID. While the banking industry is for obvious reasons heavily regulated, I don\u0026rsquo;t understand why I need to send highly sensitive documents to a provider with a low trust level. Signing up with an existing bank account or credit card might have other privacy implications but would not have the trust issues a provider like Uphold has.\nIf the web monetization protocol wants to be successful, it has to be better than existing solutions (ads). Also in terms of privacy. It is therefore paramount in my opinion that the protocol does not yield any information about the person visiting a website. But I can see a couple ways privacy could get compromised here and no documents addressing them. A particular concern I have is how tracking users across different websites is prevented given that the user is always sending from the same account. The subscription provider like Coil is another big privacy risk as they see every transaction a user is taking.\nAll this can be remedied but requires transparency and clear technical solutions.\nGetting started üåê There is a web monetization theme for hugo (the framework I use for this site) that allows for easy integration of web monetization.\nFirst I added the hugo-webmonetization-component as second theme to my site:\ngit submodule add git@github.com:sabinebertram/hugo-webmonetization-component.git themes/webmonetization Then I changed my theme in the config.toml as follows:\ntheme = [\u0026#34;gohugo-theme-ananke\u0026#34;, \u0026#34;webmonetization\u0026#34;] And then set my payment pointer in the params section of the config.toml:\n[params] monetization = \u0026#34;$ilp.uphold.com/NMNKYReeKNNw\u0026#34; In order to actually use the monetization parameter I added it to the ananke theme\u0026rsquo;s \u0026lt;head\u0026gt;. The head is defined in themes/gohugo-theme-ananke/layouts/_default/baseof.html, which includes a head-additions.html where we can add the monetization partial.\n{{ partial \u0026#34;webmonetization.html\u0026#34; .}} Sample exclusive content üíé In hugo it is simple to add exclusive content with the following short code. {{ % exclusive % }} ... exclusive content ... {{ % /exclusive % }} Note that this only works if blackfriday is used as markup engine and things like markdown code blocks don\u0026rsquo;t work in there. This might be a shortcoming of the hugo theme I\u0026rsquo;m using here.\n[markup] defaultMarkdownHandler = \u0026#34;blackfriday\u0026#34; ‚ö†Ô∏è I switched to a new theme on this blog that does not support webmonetization right now!\nIssues I encountered üêû First this only worked on the main page after following the instructions. It turned out that I had to update my hugo theme to get support on every page.\nThe description on the web monetization theme appears to be a little outdated. It is even easier to include it now.\nThe consumer side - Coil üë©üèæ‚Äçüíª To see how consumers visiting a website experience web monetization I used Coil. With an account and an extension for your favourite browser we see that it is working.\n \nThoughts on the user experience ü§î Seeing the green $ when visiting a page that uses web monetization shows the user that they are supporting the content creator and feels good. However, it takes a while for the monetization to kick in such that it looks like the page refreshes after a second for exclusive content.\n \nIt is also not entirely clear how the membership works from the popup. In particular what\u0026rsquo;s included and how the money gets distributed. But this might be a trade-off for the sake of usability. A more detailed information panel would be nice though. The mobile Puma browser is a little better here.\nOverall this reminds me a little of the donation system Amazon is running through smile.amazon.com, which is great idea but not very transparent (though this improved over time).\n   Conclusion üöß First, I really like the idea of allowing users to give money directly to websites and content creators. It is also relatively easy to get web monetization set up on a website. If this is through integration in a framework or by manually adding the header tag.\nMy two main concerns are around privacy and the state of tooling. This is obviously not a final standard such that some hiccups are to be expected. Issues around more mature tools such as Uphold are a little more concerning though. To judge the real privacy impact a more in depth analysis of the standard as well as the implementations and services are needed. But it is worrying that the specification doesn\u0026rsquo;t even mention privacy implications.\n Update I was pointed to a blog post on privacy in Coil that explains how they use privacy pass for user privacy (there\u0026rsquo;s an IETF working group in the process of standardising privacy pass) and something they call wallet privacy.\nI also filed a spec issue to get more explicit privacy treatment in the spec.\nUpdate 2 I mentioned above that Uphold appears to be dubious. Now that they disabled my account I have to disable the web monetization experiment on this page. I don\u0026rsquo;t really care, but Uphold appears to be as bad as I expected. There was no communication whatsoever from Uphold except the following screen when logging in.\n \nWhile being logged in it actually says \u0026quot; Uphold is currently unavailable\u0026quot; ü§∑üèª‚Äç‚ôÇÔ∏è\nUpdate 3 After getting in touch with Uphold (thanks Kaily!) it turned out that the account verification didn\u0026rsquo;t go through for some reason and I had to redo it to unlock my account.\nI got an innocuous email saying\n We‚Äôve had to temporarily restrict your account while we gather some more information. You can still trade but you won‚Äôt be able to withdraw funds.\n What this actually meant is that I had to get in touch with the Uphold support team to figure out what\u0026rsquo;s going on.\nI re-enabled web-monetization on this page. While the initial experience on my end wasn\u0026rsquo;t great it was unrelated to web-monetization and due to some shortcomings in Uphold\u0026rsquo;s communication and me ignoring some of it üò¨.\n","date":"2021-02-14T00:00:00Z","image":"https://www.franziskuskiefer.de/p/web-monetization/hero_hu3d03a01dcc18bc5be0e67db3d8d209a6_678427_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.franziskuskiefer.de/p/web-monetization/","title":"üí≤ Web Monetization üí≤"},{"content":"I don\u0026rsquo;t like to write a post like this but I really feel that this one is necessary. After not even half a year I\u0026rsquo;m going to leave the Fraunhofer AISEC at the end of May. In this post I want to explain why.\nThis is not a post about contact tracing!\nDuring the week of April 13 the controversy around PEPP-PT started to heat up. Articles from coindesk and other media such as Golem (German), started to pop up and I started to get a little concerned knowing that AISEC is part of the PEPP-PT organization. This quickly changed from being a sensible thing done by some people in the organization that employs me to something pretty sketchy that I definitely wanted to learn more about. Note that I haven\u0026rsquo;t been involved in any of the contact tracing approaches at AISEC or anywhere else.\nThere were three separate points that concerned me.\n Everything I have seen pointed to an approach to contact tracing that has huge potential to being abused. An approach that needs careful consideration and maybe shouldn\u0026rsquo;t be used in the first place. But without knowing any details I could hardly tell if this was really the case. The way PEPP-PT and AISEC communicated not only with the public but, as it appeared, also with other members of the consortium and employees, didn\u0026rsquo;t seem compatible with my understanding of responsible science, which requires an open discussion. This situation started to shed a bad light on everyone working for AISEC who\u0026rsquo;s taking privacy and open communication on such an important topic seriously.  In order to be able to judge the situation a little better and potentially help the necessary discussion around privacy in contact tracing apps I decided to reply to the only e-mail I had on the topic. This was before anything was published by PEPP-PT or AISEC. On April 1st when PEPP-PT was launched the AISEC director Claudia Eckert sent out an e-mail informing everyone that AISEC was part of PEPP-PT (press release from AISEC on that day in German). I noted that the optics were pretty bad and other institutions such as ETH Z√ºrich left PEPP-PT. In particular, I wanted to know\n in which way AISEC is involved in PEPP-PT and how the future collaboration is supposed to look like; how the institute wants to ensure that the situation doesn\u0026rsquo;t deteriorate any further (prevent further loss in credibility); when specifications, security models, and code would be published.  I didn\u0026rsquo;t want to get involved in any (public) discussion before knowing what\u0026rsquo;s going on. Asking internally, the person who should know, seemed like the obvious way to go.\nThe response was a little disappointing.\nI won\u0026rsquo;t disclose any content of internal e-mails. But the last sentence said that I\u0026rsquo;m of course free to hand in my notice and leave AISEC at any time.\nSo that\u0026rsquo;s what I\u0026rsquo;m doing. I leave. This is not an organization I want to work for. Neither does the behavior of AISEC as part of PEPP-PT reflect my understanding of research, science, and social responsibility, nor does the response of the AISEC leadership demonstrate an environment in which I want to work.\n(While I got a half-hearted explanation relayed a week later that tried to explain the e-mail with stress and the influx of many hostile e-mails, I believe that it is a symptom of a disrespectful culture within the organization. Actually, I haven\u0026rsquo;t heard from Claudia Eckert since that e-mail.)\n So if you are interested in hiring me, send me an e-mail (mail@ this domain).\n","date":"2020-05-04T00:00:00Z","image":"https://www.franziskuskiefer.de/p/im-leaving-aisec/hero_hu3d03a01dcc18bc5be0e67db3d8d209a6_666079_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.franziskuskiefer.de/p/im-leaving-aisec/","title":"I'm leaving AISEC"},{"content":"At the Berlin Crypto this month we had a talk by Kevin about a shared-secret service they developed at Syselevn. After experimenting with PGP and deciding that it doesn\u0026rsquo;t do what they needed, they decided to go with a very simple, custom encrypt-then-mac scheme. You can find details here. When someone says they built their own encryption scheme and message format I get obviously curious. In this post I want to summarize the scheme, design decisions, compare it standard authenticated encryption schemes, and ponder the question of the right security definitions.\nNote that I refrain from formal definitions in this post. I only want to give the intuition. Please read the linked documents for formal definitions and details. See for example the Authenticated Encryption paper by Bellare and Namprempre for details on authenticated encryption and the Authenticated Encryption with Associated Data by Rogaway on AEADs.\nShared-Secrets The service and scheme are described as follows:\n Shared-Secrets is an application that helps you to simply share one-time secrets over the web. Using the Shared-Secrets service allows you to transfer the actual secret in an encrypted form. Retrieving the secret is as simple as following a link. In contrast to other secret sharing services, Shared-Secrets does not store the secret on the server, but puts the encrypted secret into the link that you share with the desired recipient.\n I leave aside the fact that any attacker that can intercept the message can trivially retrieve the secret and focus on the encryption scheme used for the service. Note that the service allows to encrypt the message with a password before sharing it to prevent the aforementioned attack.\nThe encryption scheme used for this service is a basic encrypt-then-mac scheme that can be written as\n(c, t) \u0026lt;- EtM(key, nonce, msg, aad) where aad contains all meta-data (version etc.). Keys for the mac and encryption algorithms are derived as follows\nkey \u0026lt;- random() # 32-byte (k_c, k_t) \u0026lt;- (HMAC-SHA256(key, \u0026quot;enc\u0026quot;), HMAC-SHA256(key, \u0026quot;mac\u0026quot;)) rsakey \u0026lt;- RSA-OAEP(pk, key) The RSA key pk is the server\u0026rsquo;s public key. Now we can compute the ciphertext and mac.\nc \u0026lt;- AES-256-CTR(k_c, nonce, msg) t \u0026lt;- HMAC-SHA256(k_t, aad, c) The message format is defined as\n[version:01][rsakeycount:02][rsakeyid:32][rsakeylength:02][rsakey:mm][...][rsakeyid:32][rsakeylength:02][rsakey:mm][nonce:16][message:nn][mac:32] with rsakeyid := SHA256(pk) and nonce := $(date +%s)|0..0 (8-byte unix timestamp, padded 8 zero bytes).\nObservations Looking at the scheme there are a two things that stand out. This is in addition to the unclear threat scenario that I won\u0026rsquo;t discuss in this post.\nNote that there\u0026rsquo;s currently no standardized way of doing hybrid encryption. There\u0026rsquo;s currently an RFC in the making but until that\u0026rsquo;s finished it is necessary to define custom hybrid schemes as done here.\nThe nonce is not random When using encryption schemes such as AES-CTR it is paramount that the nonce is unique. If this is not the case, the key-stream becomes known and allows full message recovery. Using a timestamp as nonce is usually a bad move as time is predictable and not random.\nHow is this different from an AEAD The scheme as described above looks like an AEAD scheme. So the question is why didn\u0026rsquo;t they just use an established AEAD scheme such as AES-GCM or ChaCha20Poly1305.\nEncrypt-then-Mac == AEAD? Let\u0026rsquo;s talk about encryption and authentication first. Historically encryption offered confidentiality but no integrity. Something that\u0026rsquo;s not immediately obvious to non-cryptographers who want to use encryption to protect their data. Authenticated Encryption (AE) and its relation to non-authenticated encryption was first described in the previously mentioned paper by Bellare and Namprempre in 2000.\nEncryption was considered secure if it satisfied the indistinguishable under chosen plaintext property, i.e. if an attacker couldn\u0026rsquo;t distinguish whether a ciphertext encrypts message a or message b. But \u0026ldquo;security\u0026rdquo; of an encryption scheme intuitively might mean something else as well. In addition to not being able to know which message is encrypted in a ciphertext it shouldn\u0026rsquo;t be possible for an attacker to change the content of the message or the ciphertext without the recipient noticing it. This property can be described as ciphertext (or plaintext) integrity and allows the definition of authenticated encryption. Adding associated data (AD) that is not encrypted but authenticated we get Authenticated Encryption with Associated Data (AEAD). For a comprehensive overview of AEAD and its history I recommend checking out these slides by Phillip Rogaway.\nEncrypt-then-Mac != AEAD Generally encrypt-then-mac schemes can be considered AEADs. For this to be true however, the Mac has to be strongly unforgeable. Luckily this is the case for HMAC such that the scheme described above is fine in this regard.\nA MAC scheme is weakly unforgeable (WUF-CMA) if an attacker is not able to generate a tag for a new message, i.e. a message that she hasn\u0026rsquo;t seen a tag for before. If a scheme is strongly unforgeable (SUF-CMA), it must me impossible for an attacker to generate a new message, tag pair, i.e. not only a new message but also a new tag. While SUF-CMA seems like an artificial extension of the intuitive notion of WUF-CMA it is necessary to build an AEAD as WUF-CMA doesn\u0026rsquo;t provide integrity guarantees for the ciphertext or plaintext.\nAEAD Properties The motivation to build this custom AEAD scheme instead of using an existing one was a big point of discussion at the meetup. The essence is that Kenny didn\u0026rsquo;t trust that an AEAD provided exactly what he needed. So what are properties of an AEAD? Generally AEADs are supposed to offer IND-CCA security where the attacker is allowed to decrypt arbitrary ciphertexts. Instead of thinking of AEAD as IND-CCA secure it is more intuitive to think of it as IND-CPA secure (i.e. the attacker can\u0026rsquo;t do better than guessing which message is encrypted in a ciphertext when given the ciphertext to one of two adversarially chosen messages) and offering INT-CTXT, i.e. integrity of the ciphertext. Note that this does not imply authenticity of the plaintext because IND-CCA does not guarantee that it is impossible for an attacker to generate a valid ciphertext for a specially crafted message.\nUniqueness of Tags The property that was questioned to be part of the AEAD security definition but was important to the Shared-Secrets service is the uniqueness of the ciphertext and tag. This is necessary to make sure secrets can only be retrieved once. According to the website the server uses a fingerprint to achieve this. First I notice that fingerprint is not defined in the encryption scheme. Looking at the code it appears that the fingerprint is the tag. The fingerprint is stored on the server and the service refuses to decrypt anything with the fingerprint if it did so once before.\nSo the question is whether the used encrypt-then-mac scheme makes sure that the tag is unique and whether an AEAD would have offered this property as well.\nIn other words, can an attacker generate a second, different, valid tag t' for an existing ciphertext, tag pair (c, t). Note that I do not consider encodings here. (Using base64 encoding for example it is possible to generate two different base64 strings that decode to the same binary message.) To this end there has to exist a pair (c, t), (c', t') with Dec(c) == Dec(c') \u0026amp;\u0026amp; Verify(t) == Verify(t') i.e. two ciphertext, tag pairs that decrypt to the same message and both tags are valid. First note that the unforgeability of the Mac ensures that it is impossible to generate a valid tag t' for a given ciphertext c without knowledge of the key. It follows that the ciphertext c' has to be different from the original ciphertext c. But without knowledge of the message m encrypted in c (or the key) it is impossible to generate a ciphertext c' that decrypts to m. Hence this is not possible.\nWhile everything else in this post were well established properties of AEADs this one doesn\u0026rsquo;t appear to follow trivially. However, this applies to the custom scheme used in Shared-Secrets as well as an off-the-shelf AEAD.\nTimestamps as Nonces Non-random nonces break most AEAD schemes. This is one reason Misuse-Resistant AE (MRAE) was introduced and specified for schemes such as AES-GCM (AES-GCM-SIV).\nSo how does choosing a timestamp as nonce fare in the Shared-Secret scheme?\nRecall that AES in counter mode, as used here, is an XOR of a plaintext block with the AES encryption of the concatenation of the nonce and the counter (c_i = m_i xor AES(key, nonce||ctr)). Thus, one can recover an unknown plaintext by computing the xor of its ciphertext with the xor of a known ciphertext, plaintext pair (m_i = c_i xor (c'_i xor m'_i)) when the nonce is known.\nWhile the Shared-Secrets scheme is very fragile here and not well-designed here (why not just take a random nonce?) I can\u0026rsquo;t see how this can be exploited. Even if an attacker is able to generate two ciphertexts with the same nonce (this can be easily done by sending two requests to the server at the same time), the key will be different in both cases.\nDiscussion: How to define security? This episode illustrates how important it is for security definitions to model real-world scenarios that people actually have when using a primitive. But it also shows that sometimes, even though standard primitives with appropriate security definitions exist, communicating these properties fail. The use case of the Shared-Secrets is a peculiar one but highlights these issues. Something I did not expect is that people rather define their own crypto schemes than using existing ones because they think they don\u0026rsquo;t understand the properties properly. But this is all the more reason to make sure the exact security properties a scheme offers are communicated and well understood by everyone.\nFor me this is another pointer that it is important to have properly working communication channels between people analyzing crypto and everyone using it in order to transport requirements and make sure everyone is on the same page. And this is, among others things, what we do at the Berlin Crypto meetup in a very informal and local setting.\n","date":"2019-12-23T00:00:00Z","image":"https://www.franziskuskiefer.de/p/shared-secrets-service/hero_hu3d03a01dcc18bc5be0e67db3d8d209a6_233668_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.franziskuskiefer.de/p/shared-secrets-service/","title":"Shared-Secrets Service"},{"content":"Last week we had the third Security Engineering University Relationship Framework (SURF) summit in Vienna. The last SURF summit I attended was the first one in London 2018.\nThis time we had four talks by Mozillians, three invited talks, as well as eight lightning talks. I live-tweeted a little during the event if you like slides on photos.\nChristoph talked about how to harden the content security landscape of Firefox and posed the question how we could do some of that on the web. The web PKI with all its problems was the topic of Thyla\u0026rsquo;s talk, with a focus on CRLite. There\u0026rsquo;s also a blog post on the Mozilla security blog on this with more details and links.\nOne prominent topic at this SURF summit was how to preserve privacy online and counter tracking. Natliia gave an invited talk on detecting trackers missed by filter lists and browser extensions, Steven talked about challenges in building a private web and Gunes about dark patterns and how to find them on the web.\nOn the crypto side we had Kenny talk about API design of crypto primitves and primality testing. Details can be found in the well titled papers safety in numbers and prime and prejudice. I talked about Post Quantum Crypto and Mozilla calling on more experiments with post quantum crypto beyond TLS key exchange.\nWe closed the summit with a panel discussion on the gap between theory and practice.\n","date":"2019-11-12T00:00:00Z","image":"https://www.franziskuskiefer.de/p/mozilla-surf-summit-vienna-2019/surf-vienna-2019_huaa633ee67b331d6271e981a9566aa9b0_3639369_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.franziskuskiefer.de/p/mozilla-surf-summit-vienna-2019/","title":"Mozilla SURF Summit Vienna 2019"},{"content":"One of Rusts great feature is that it catches integer overflows at runtime and panics rather than wraps (in debug builds). I recommend you read Huon\u0026rsquo;s blog post about this from a couple years ago.\nWhile this is a desirable behaviour in general, integer overflows are commonly used when implementing cryptography primitives. Rust offers wrapping alternatives such as wrapping_add etc. to allow wrapping behaviour. However, this makes code very hard to read, e.g. let c = a + b is easier to read than let c = a.wrapping_add(b).\nOther wrapping arithmetic Rust itself provides a wrapping integer type in std::num::Wrapping.\nusestd::num::Wrapping;letzero=Wrapping(0u32);letone=Wrapping(1u32);assert_eq!(std::u32::MAX,(zero-one).0);This is a good solution when you want to be explicit about what you\u0026rsquo;re doing. However, its readability is still not great.\n#[wrappit] To alleviate this shortcoming I implemented a procedural macro that rewrites arithmetic operators +,-,* into their wrapping equivalents wrapping_add, wrapping_sub, wrapping_mul as well as their assigning versions +=,-=,*=.\nThe following function for example\n#[wrappit]fn mix(a: u32,b: u32,c: \u0026amp;[u32])-\u0026gt; u32 {letmutr=a+b;foruinc{r*=u;}r}is rewritten to\nfn mix(a: u32,b: u32,c: \u0026amp;[u32])-\u0026gt; u32 {letmutr=a.wrapping_add(b);foruinc{r=r.wrapping_mul(u);}r}You can find wrapping_arithmetic on GitHub and on crates.io. To use #[wrappit] add wrapping_arithmetic = \u0026quot;0.1\u0026quot; to your cargo.toml.\n","date":"2019-10-21T00:00:00Z","permalink":"https://www.franziskuskiefer.de/p/wrapping-arithmetic-in-rust/","title":"Wrapping arithmetic in Rust"},{"content":"Earlier this year I introduced hacspec, a new specification language for cryptographic primitives. After Karthik presented the idea and very preliminary results at IETF 101 in March we made quite some progress and presented a paper with a little more detail at SSR earlier this week. In this blog post I\u0026rsquo;ll give the gist of the SSR paper and introduce the first version of hacspec.\nAll information about hacspec can be found at https://hacs-workshop.github.io/hacspec/.\nThe language The hacspec language is a DSL for cryptographic algorithms. But it can also be seen as a typed subset of Python. The following describes the language.\n Values v ::= n integer constants | True | False boolean constants | '...' | \u0026quot;...\u0026quot; string constants | (v1,...,vn) tuple constant | array([v1,...,vn]) array constant Expressions e ::= v values | x | m.x local and global variables | (e1,...,en) tuple construction | array([e1,...,en]) array construction | array.length(e) array length | e[e0] array access | e[e0:e1] array slice | e(e1,...,en) function call | e1 binop e2 builtin binary operators | unaryop e builtin unary operators Types t ::= int, str, bool basic types | tuple_t(t1,...,tn) tuples | vlarray_t(t) variable-length array | x user-defined or builtin type | x(t1,...,tn,e1,...,em) builtin type application Statements s ::= x: Type = t type declaration | x: t variable declaration | x = e variable assignment | x binop= e augmented variable assignment | (x1,..,xn) = e tuple matching | x[i] = e array update | x[i] binop= e augmented array update | x[i:j] = e array slice update | if e: if-elif-else conditional s1...sn elif e: s1'...sn' else s1''...sn'' | for i in range(e): for loop s1...sn | break break from loop | def x(x1:t1,...,xn:tn) -\u0026gt; t: function declaration s1 ... sn | return e return from function | from x import x1, x2,..., xn module import Specs œÉ ::= s1...sn sequence of statements hacspec architecture The hacspec architecture is depicted in the following graph.\n \nWriting hacspec Every spec should be accompanied by a test and some test vectors leaving the author with at least two files, e.g. poly.py and poly_test.py (also see Example section). Note that only the spec file has to be hacspec syntax. The test file can make use of all of Python. hacspec comes with a standard library called speclib and a spec-checker. To use the hacspec speclib and spec-checker install them via pip install hacspec or from the source (the setup.py for the Python package can be found in /build/). Running hacspec requires a Python interpreter version 3.6.4 or newer.\nspeclib Commonly used functionality is provided in speclib (from hacspec.speclib import *). The full speclib documentation can be found here. Some highlights are\n modular arithmetic: natmod_t is an integer data type that provides modular arithmetic, e.g. felem_t = natmod_t((2**130)-5) defines field elements modulo (2**130)-5. machine integers: unitN_t define commonly used machine integer types for N = 8, 16, 32, 64, 128. byte arrays, vectors, and matrices: provided data structures are array_t, bytes_t, vector_t, matrix_t as well as the variable length versions vlarray_t and vlbytes_t. Note that the vector and matrix data types offer point-wise arithmetic. refinements: refine_t allows to refine data types. contracts: @contract annotation on functions can be used for pre- and post-conditions.1  spec-checker Since hacspecs are executed with a Python interpreter it is not sufficient to run hacspec to check their syntax. To check that the syntax is valid a spec-checker is provided.2\nhacspec-check \u0026lt;your-hacspec\u0026gt; Executing hacspec hacspec tests are executed with the Python interpreter. Executing tests on a spec can yield three different results.\n The execution is successful and all test vectors pass. In this case the spec is most likely correct and doesn\u0026rsquo;t contain any obvious typing issues. The execution fails because of a failing test case. In this case the spec is probably wrong (or the test vectors are incorrect). The execution fails because of a type error. The speclib as well as typeguard are used to perform runtime type checks.  Checking and compiling hacspec To use hacspecs for formal verification such as verification of cryptographic properties of an algorithm, generating code in other languages from the spec, or verifying correctness of other implementations with it, a second set of tools is provided. These tools are written in OCaml and thus require additional setup and are not packaged right now.3 Check out the repository to use them. All tools can be easily called via make (see documentation in the repo /compiler/ for details).\nType checker To perform proper type checking Python is impractical. A native type checker is implemented in OCaml that performs syntax and type checking for hacspec. To run the type checker on a spec simply run ./checker.native \u0026lt;your-spec\u0026gt;.\nCompiler The type checker also produces a typed AST that can be used to generate the spec in another formal language. There are currently compiler for EasyCrypt and F*. I\u0026rsquo;ll only describe the F* compiler as it\u0026rsquo;s more complete.\nF* compiler The F* compiler requires HACL_HOME and FSTAR_HOME environment variables to be set. The compiler is then invoked like this ./to_fstar \u0026lt;your-spec\u0026gt;. The generated F* spec can then be type checked or executed on test vectors to check correctness of the spec. Using kremlin the F* code can also be used to generate C code.\nExample The hacspec repo has many examples. I\u0026rsquo;ll only give a short one here.\nThe spec poly.py:\nfrom hacspec.speclib import * p130m5: nat_t = (2 ** 130) - 5 felem_t = natmod_t(p130m5) @typechecked def felem(n: nat_t) -\u0026gt; felem_t: return natmod(n,p130m5) @typechecked def poly(m: vlarray_t(felem_t), r: felem_t) -\u0026gt; felem_t: acc: felem_t = felem(0) for i in range(array.length(m)): acc = (acc + m[i]) * r return acc The test poly_test.py:\nfrom poly import * def main(): m = array([felem(0x6f4620636968706172676f7470797243), felem(0x6f7247206863726165736552206d7572)]) k = felem(0xa806d542fe52447f336d555778bed685) expected = natmod(0xa01b776a69ea8c1cd3ba00179dc218ab, p130m5) p = poly(m,k) if not expected == p: print(\u0026#34;Error\u0026#34;) print(\u0026#34;Expected: \u0026#34; + str(expected)) print(\u0026#34;Got: \u0026#34; + str(p)) else: print(\u0026#34;Test successful\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() This can now be run with python poly_test.py and checked with hacspec-check poly.py and checker.native poly.py. Compiling this to F* can be done with to_fstar.native poly.py, generating the following F* code.\nmodule Poly open Speclib let p130m5 : nat_t = (2 **. 130) -. 5 let felem_t : Type0 = natmod_t p130m5 let felem (n : nat_t) : felem_t = natmod n p130m5 let poly (m : vlarray_t felem_t) (r : felem_t) : felem_t = let acc = felem 0 in let acc = repeati (array_length m) (fun i acc -\u0026gt; (acc +. m.[i]) *. r) acc in acc Next steps We hope that hacspec is a useful tool for spec authors and many people indeed voiced interest already. While the tooling isn\u0026rsquo;t perfect yet, the language is developed enough to start using it. The next steps for hacspec is to get some usage from spec authors and improve tooling. We also hope to get more compilers for different formal languages implemented.\n  Note that contracts are still in development and not fully supported yet. In future hacspec syntax checks and running test vectors on the spec should be done in one invocation. In future pre-built binaries should be distributed to make this easier.  hacspec is mostly a spare time project for me at the moment. Development is therefore not always as fast as I\u0026rsquo;d like.\n","date":"2018-11-30T00:00:00Z","image":"https://www.franziskuskiefer.de/p/update-on-hacspec/hacspec2-architecture_hu59cb5aa3cd237429216159464502cf06_303676_120x120_fill_box_smart1_3.png","permalink":"https://www.franziskuskiefer.de/p/update-on-hacspec/","title":"Update on hacspec"},{"content":"The Security Engineering University Relationship Framework (SURF) is an initiative within the Firefox security engineering team to improve relations with privacy and security researchers. SURF includes a variety of possible relationships but is focused on building long-term relationships with researchers and organisations. The goal of SURF projects is to explore topics that are outside of Mozilla\u0026rsquo;s immediate product needs, influence Mozilla\u0026rsquo;s long-term product development and vision.\nOn November 12th the first SURF summit was held in London. SURF summits are an opportunity for researchers and Mozillians to get together and exchange ideas. This very first summit, organised by Thyla, was attended by a number of Mozillians, UK academics, and grad students.\nFour Mozillians presented challenges they are currently facing, pitching possible research challenges.\n Steven Englehardt talked about the need for tracking protection Christoph Kerschbaumer talked about preventing data exfiltration from the browser I talked about securely implementing cryptography Thyla van der Merwe talked about Tor at scale  There were also two invited speakers. Lorenzo Cavallaro introduced us to TESSERACT, an attempt to elliminate experimental bias in malware classification systems. And Stefan Brunthaler talked about software diversity as possible solutions to spectre-like attacks (no slides online yet). In two rounds grad students also presented ongoing work on MPC, Primality Testing, Blockchains, and UnlimitID in lightning talks.\n","date":"2018-11-19T00:00:00Z","permalink":"https://www.franziskuskiefer.de/p/mozilla-security-research-summit-london-2018/","title":"Mozilla Security Research Summit London 2018"},{"content":"If you didn\u0026rsquo;t read the article about the HACL* approach, go there first and read it. tl;dr\n HACL* is a cryptographic library written in F* that allows translation to C using kremlin. It guarantees memory safety, secret independent computation, and functional correctness with respect to a mathematical specification.\n  In this second blog post I describe the process of integrating code from HACL*, a researchy crypto library, into NSS, a production library shipping to millions of people, running on a plethora of platforms. In short, how to ship (some parts of) HACL*.\nShipping formally verified code Before integrating any code from HACL* into NSS there had to be some criteria the code had to fulfil in order to get considered and a process of integrating, maintaining, and updating the code. The criteria roughly looked like this:\n The code has to be correct. Performance must not be degraded by any new code. The code has to be human readable and modifiable, i.e. it must pass a code review process. The code must run on all platforms supported by NSS or must have fallback code for platforms that are not supported. Upstream changes can to be integrated easily into NSS and fixes can be integrated upstream. The verification and generation toolchain has to run in the NSS world.  We started integrating HACL* crypto primitives into NSS with Curve25519. At the time of writing NSS contains code from HACL* for Curve25519 64-bit, Poly1305 32-bit and 64-bit, ChaCha20, and ChaCha20 with SSSE3 hardware acceleration. More primitives are in the pipeline and will be integrated in the near future.\nCorrectness Any code that lands in NSS has to be correct, obviously. This might be evident but when talking about HACL* generated C code, correctness is not so simple. Correctness can be checked relatively easily by looking at the HACL* specification of a given primitive. This code is relatively easy to review (when familiar with F*) as it closely resembles the mathematical specification of the primitive. The correctness of the C code is guaranteed by the formal proofs from HACL*. In addition we run all the usual test vectors on it of course. To catch any errors in the extraction chain from F* to C the extracted C code is reviewed for correctness as well.\nPerformance Performance was not a big concern. As shown in the HACL* paper from CCS 2017, performance of most primitives is on par with or better than the fastest C implementations out there. Nonetheless, performance of each primitive is compared between HACL* and the NSS to make sure not to degrade performance. For every primitive I looked at so far the performance of HACL* was at least as good as the performance of the NSS code.\nCode quality Code quality was, as with any generated code, a big concern. How readable is the generated code? Can it easily be changed if the need arises? The first versions we looked at weren\u0026rsquo;t that great \u0026hellip;\n   \nBut after a couple improvements to kremlin the code was good to go. While every new piece of code that\u0026rsquo;s being integrated has to pass code review the C code produced by kremlin is good enough now to land new primitives without having to improve upstream code first. Note however that code passes review here that wouldn\u0026rsquo;t pass if it were hand-written. The code generator is not perfect. We have to live with some rough edges. The most important point is that the code is understandable.\nNSS if formatted with clang-format, which is checked on CI. So the only change to the verified C code imported from HACL* is formatting.\nSome pain points remain There are some outstanding issues that I hope get fixed in kremlin and would improve code quality significantly. Kremlin doesn\u0026rsquo;t know const, which is one of the few nice helpers one can use in C to control what\u0026rsquo;s happening to your pointer. While const is not necessary because of the HACL* proofs, it would be nice to have. Kremlin further generates unnecessary casts such as (uint32_t)4U. This is not a big deal but makes code harder to read. There\u0026rsquo;s also a big number of temporary variables that aren\u0026rsquo;t necessary and make the code harder to read.\nPlatform support Being a researchy library HACL* is not tested on a big variety of platforms. NSS on the other hand has to run on most available platforms as well as a number of legacy platforms. While the NSS CI covers Windows, Linux, and Mac in different configurations such as Intel 32-bit, 64-bit, and aarch64, there are other platforms such as BSD using NSS that are not covered. As expected we ran into a couple issues on some platforms such as BSD and Solaris but they were quickly resolved.\n \n \nEspecially code that is hardware dependent such as Intel intrinsics needs extra attention. The vec128.h header used by HACL* to abstract hardware instructions needed a couple iterations before it worked on all supported platforms.\nHandling change The code imported from HACL* into NSS is not expected to change a lot. But there are always reasons why the code has to get updated and a process is required to do so. To fix issues like broken platforms, changes to the upstream projects have to be landed and the snapshot in NSS has to get updated to the new upstream version. For this process to run smoothly it\u0026rsquo;s necessary for both teams to work together.\nUpdating the HACL* code in NSS is pretty easy. First the new code is generated with a new version of HACL*, formatted, and copied to NSS. Then the docker image running the CI gets updated. Here\u0026rsquo;s a diff for a recent update.\n \nRunning the verification in NSS To make sure that whatever we use in NSS actually verifies and the generated code isn\u0026rsquo;t changed manually, the NSS CI has to verify the HACL* snapshot it uses on every run. NSS uses taskcluster as CI, which allows us to use a docker image that re-verifies the used HACL* revision on every push. Checking the code in NSS is then a simple diff.\nLessons learned The first lesson is that it\u0026rsquo;s possible to ship formally verified software. The code is relatively simple and self-contained, which makes this easier. But it shows that formal verification tools are good enough to be used in production.\nThe second lesson we learned is probably the more valuable one.\n Talk to each other and work together.\n From an engineering standpoint it might be frightening to start looking at formal verification tools and corresponding languages. But people working with these tools are happy to help out if that means more people are using their tools. It will need some effort getting used to the tools and languages but it\u0026rsquo;s well worth it.\nFor people working on formal methods; You might have to learn a little more than you wanted to know about differences between different platforms and compilers and how to ship software. But that might be worth the effort if it means your proofs are used in production software that\u0026rsquo;s used by millions of people.\n Looking for more material on this? There\u0026rsquo;s a high-level blog post that talks about the formal verification work in NSS happening at Mozilla. There has also been a talk at RWC 2018 earlier this year on this work (slides, video).\n","date":"2018-04-12T00:00:00Z","image":"https://www.franziskuskiefer.de/p/shipping-some-hacl/hero_hu3d03a01dcc18bc5be0e67db3d8d209a6_420155_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.franziskuskiefer.de/p/shipping-some-hacl/","title":"Shipping (some) HACL*"},{"content":"HACL* (High-Assurance Cryptographic Library) is a formally verified cryptographic library in F*, developed by the Prosecco team at INRIA Paris in collaboration with Microsoft Research, as part of Project Everest. HACL* was inspired by discussions at the HACS workshop and aims at developing a set of reference implementations in C for common cryptographic primitives.\nThis is the first post in a series describing formal verification in NSS as an approach to improve confidence in highly complex, highly security critical code. In this first post I describe the most important ideas and concepts of HACL*, the basis of most formally verified code in NSS. If you want to have all the juicy details about HACL*, I recommend reading the CCS'17 paper.\nHACL* HACL*, though written in F*, can be compiled to C code with guaranteed memory safety, secret independent computation, and functional correctness with respect to some mathematical specification. Let\u0026rsquo;s first have a look at the high-level idea of HACL* on the example of Curve25519.\nThe first step is to take the specification (RFC 7748 in this case) and translate it into a high level F* specification. This specification is easy to read and can be checked for correctness against the RFC easily. All correctness guarantees HACL* gives for the generated C code are based on this specification, i.e. the C code is proven to be functionally equivalent to the the high level specification. Here the definition of the Montgomery ladder, an excerpt from the Curve25519 specification. (Apologies for the highlighting, no F* support.)\n1let rec montgomery_ladder_ (init:elem) x xp1 (k:scalar) (ctr:nat{ctr\u0026lt;=256}) 2 : Tot proj_point (decreases ctr) = 3 if ctr = 0 then x 4 else ( 5 let ctr\u0026#39; = ctr - 1 in 6 let (x\u0026#39;, xp1\u0026#39;) = 7 if uint_to_nat (ith_bit k ctr\u0026#39;) = 1 then ( 8 let nqp2, nqp1 = add_and_double init xp1 x in 9 nqp1, nqp2 10 ) else add_and_double init x xp1 in 11 montgomery_ladder_ init x\u0026#39; xp1\u0026#39; k ctr\u0026#39; 12) Running the reference implementation is possible but obviously slow (it is executed in OCaml). However a subset of F* (called Low*) can be translated to C using Kremlin. While the specification might be valid Low* code it is not optimised and thus won\u0026rsquo;t yield fast C code. In order to generate fast C code more efficient Low* code has to be written first. Looking at state of the art C code for the given algorithm (Curve25519 Donna for example) Low* code can be written that resembles the fast C code and can be extracted via Kremlin to similarly looking C code.\nAt this point the main benefit of the HACL* approach comes to light. The optimised Low* code (as well as the extracted C code) are hard to get right and even harder to review for correctness, memory safety, and secret independent execution. Using an SMT solver (Z3 is used in HACL*) and F*\u0026rsquo;s strong type system, functional equivalence is proven between the high-level F* specification and the optimised Low* code. The Low* code usually has to be enhanced with additional information to help prove the equivalence. This additional code however is ignored by Kremlin and doesn\u0026rsquo;t get translated to C.\nThe following graphic gives an overview of the HACL* process.\n \nAn Example - Conditional Swap HACL* is a pretty complex library and it might be hard to understand what\u0026rsquo;s going on. Therefore I\u0026rsquo;ll give a small example of the basic concepts behind HACL* focusing on functional correctness.\nConditional swaps are used for example in Curve25519 implementations to swap two variables a and b if a certain condition is given, c = 0 here. In F* this can be written as follows.\n1val cswap: x:uint32 -\u0026gt; y:uint32 -\u0026gt; c:uint32 -\u0026gt; 2 Tot (uint32 * uint32) 3let cswap x y c = 4 if c = 0ul then 5 (x, y) 6 else 7 (y, x) This code can be easily inspected for correctness and is used as specification. However, this is not the code we want to have as it branches on potentially secret data in c. Instead of checking c for 0 we should use masking and logical operations to achieve the variable swapping. Note that we require c to be either all 1 or all 0 now. This can be easily computed from the single bit c we had in the previous example. This looks as follows in pseudo-C-code.\n1void cswap_constant_time(uint32_t *a, uint32_t *b, uint32_t c) { 2 uint32_t mask = (*a ^ *b) \u0026amp; c; 3 *a = *a ^ mask; 4 *b = *b ^ mask; 5} The same code in F* (with slightly different input/output behaviour) looks as follows.\n1val cswap_constant_time: x:uint32 -\u0026gt; y:uint32 -\u0026gt; c:uint32{c = 0xFFFFFFFFul \\/ c = 0ul} -\u0026gt; 2 Tot (uint32 * uint32) 3let cswap_constant_time x y c = 4 let mask = (x ^^ y) \u0026amp;^ c in 5 let a = x ^^ mask in 6 let b = y ^^ mask in 7 (a, b) This code is not trivially correct anymore and requires considerable thought by both author and reviewer. But instead of staring at the code to understand it or writing incomplete tests we can use F* now to prove that cswap_constant_time is equivalent to our spec, i.e. cswap. To this end we write a lemma to ensures that.\n1let a, b = cswap_constant_time x y c in 2let c, d = cswap x y c in 3a = c /\\ b = d While this can\u0026rsquo;t be proven immediately it is relatively easy to write some helper lemmata that help F* and Z3 to understand the correctness of this statement. The C code extracted by Kremlin from the F* code above then looks as follows.\n1typedef struct { 2 uint32_t fst; 3 uint32_t snd; 4} 5K___uint32_t_uint32_t; 6 7K___uint32_t_uint32_t Impl_CSwap_cswap_constant_time(uint32_t x, uint32_t y, uint32_t c) { 8 return ((K___uint32_t_uint32_t){ .fst = x ^ ((x ^ y) \u0026amp; c), .snd = y ^ ((x ^ y) \u0026amp; c) }); 9} Check out the repository for the full source code of the example.\nMemory safety can be proven easily as well by specifying liveliness conditions of buffers. In this example we don\u0026rsquo;t have buffers so no need for verifying memory safety. We skip proving secret-independent execution here as it requires additional support from HACL*.\nCode Generation vs Code Verification The HACL* approach as described above is a great way of generating fast C code that\u0026rsquo;s proven to be correct, memory safe, and have secret-independent runtime. For NSS we decided to use code generation and integrate code from HACL* into the code base. However, instead of generating code it would also be possible to verify existing C code with other tools such as Cryptol/SAW to prove similar properties of the code.\nThe main advantage of code generation is that the mathematical specifications can be easily used to build more complex algorithms and protocols on top and allow for re-use of specification code. The trusted code base written in F* is therefore very small.\nThe main drawback of generating code is a relatively large third-party code base that has to be trusted in order to generate the code. The weakest link in the case of HACL* is probably Kremlin, which has a hand written proof but is a relatively young piece of code that probably contains bugs.\nThere is no optimal solution to this problem that works for everyone but the HACL* approach as described in this post is a great way to get better confidence in correctness and security of complex C code using formal verification.\nIn the next post I\u0026rsquo;ll talk about challenges we faced when integrating code from HACL* into NSS and how we solved them.\n","date":"2018-02-14T00:00:00Z","image":"https://www.franziskuskiefer.de/p/the-hacl-approach/hacl-chart_hubf5385a0c6763cff9ba6bbfffd88a9a5_61924_120x120_fill_box_smart1_3.png","permalink":"https://www.franziskuskiefer.de/p/the-hacl-approach/","title":"The HACL* approach"},{"content":"HacSpec is a proposal for a new specification language for cryptographic primitives that is succinct, that is easy to read and implement, and that lends itself to formal verification. It aims to formalise the pseudocode used in cryptographic standards by proposing a formal syntax that can be checked for simple errors. HacSpec specifications are further executable to test against test vectors specified in a common syntax.\nThe main focus of HacSpec is to allow specifications to be compiled to formal languages such as cryptol, coq, F*, and easycrypt and thus make it easier to formally verify implementations. This allows a specification using HacSpec to be the basis not only for implementations but also for formal proofs of functional correctness, cryptographic security, and side-channel resistance.\nThe idea of having a language like HacSpec stems from discussions at the recent HACS workshop in Zurich. The High-Assurance-Cryptographic-Software workshop (HACS) is an invite-only workshop co-located with the Real World Crypto symposium.\nAnyone interested in moving this project forward should subscribe to the mailing list or file issues and pull requests against the Github repository.\nHow far are we? We discussed and hacked at HACS a month ago and improved a little over the last weeks. The current state can be found at Github repository.\nThe language There are examples written in what we believe could be the HacSpec. The language is valid Python 3.6 using PEP484 and PEP526 for typing. It further uses comments (similar to PEP484 types) to define lengths and ranges.\nThere are also experiments using Rust as basis for HacSpec. While Rust\u0026rsquo;s type system makes it a compelling candidate, limitations in handling integers of arbitrary size means we probably won\u0026rsquo;t be basing HacSpec on Rust.\nThe language specification is currently vague and not fully formalised yet. It lives in a markdown document but will move to an RFC layout later.\nFormal specifications To show how cryptographic primitives are modelled in formal languages we added a number of specifications in different languages such as cryptol, coq, F*, and easycrypt to the repository.\nSpec checker In order to verify whether a specification is a valid HacSpec Aaron started to implement a spec-checker. Basing HacSpec on another language like Python means that not all valid Python programs are valid HacSpec programs. The spec checker is supposed to tell authors whether a given python program is a valid HacSpec.\nCompilers There\u0026rsquo;s currently a very basic HacSpec to F* compiler from Karthik. Eventually we would like to have compilers from HacSpec to all common formal languages such as cryptol, coq, F*, and easycrypt.\nCall for participation We invite contributions in the following areas.\n We invite people to submit ‚Äústandalone\u0026quot; formal specs for inclusion in the formal-models directory. We invite formal methods people to build compilers from HacSpec to their favourite modelling language. We invite spec authors and developers to comment on HacSpec and provide examples of what they consider good crypto specs or beautiful ‚Äúobviously correct‚Äù crypto implementations. We invite developers to build compilers from HacSpec to their favourite programming language.  What HacSpec is not about HacSpec does not aim to be general enough to express protocols at this point. While this might be a target in the future the first iteration of HacSpec is only targeting crypto primitives.\nLinks  Github repository Mailing list  ","date":"2018-02-08T00:00:00Z","image":"https://www.franziskuskiefer.de/p/introducing-hacspec/hero_hu0ce6fe0d9adc29c9a4ba1507bcf5cc23_31987_120x120_fill_box_smart1_3.png","permalink":"https://www.franziskuskiefer.de/p/introducing-hacspec/","title":"Introducing HacSpec"},{"content":"On April 19, 2017, Mozilla Foundation published the Security Advisory 2017-10 outlining several recently fixed security vulnerabilities. One of these vulnerabilities, tracked as CVE-2017-5462, affects the Pseudo-Random Number Generator (PRNG) within the Network Security Services (NSS) library prior to version 3.29.5 and Firefox prior to version 53.\nThis post describes the bug and how it was discovered.\nInside the NSS PRNG NSS uses Hash_DRBG as PRNG, which is one of several PRNG schemes defined in the NIST Special Publication 800-90. Like most widely used PRNGs the Hash_DRBG is a Deterministic Random Bit Generator (DRBG). (Even though this term is usually only used for NIST PRNGs.) While the standard contains all the details, the relevant features can be summarised as follows.\nThe state of Hash_DRBG is composed of three values:\n A 55-byte integer state variable V, which is updated with each request of new bits A 55-byte integer constant C that depends on the seed and is updated when re-seeding the PRNG. A counter c tracking when the next re-seeding is needed.  To generate random bits, Hash_DRBG concatenates H(V) || H(V+1) || H(V+2) || ... until enough bits are generated. H denotes a cryptographic hash function here. NSS uses the SHA-256 hash function for H with a digest length of 32 bytes. After generating new bits the state variable V is updated according to the rule Vc+1  = V + H(0x03 || Vc ) + C + c and counter c is incremented by one. Addition is performed modulo 2440  = 28*55 to fit it in the 55 bytes of V.\nThe PRNG implementation can be found in the file drbg.c within the NSS codebase.\nCVE-2017-5462 The issue identified in CVE-2017-5462 is in the code implementing the addition.\n/* * build some fast inline functions for adding. */ #define PRNG_ADD_CARRY_ONLY(dest, start, carry) \\ { \\ int k1; \\ for (k1 = start; carry \u0026amp;\u0026amp; k1 \u0026gt;= 0; k1--) { \\ carry = !(++dest[k1]); \\ } \\ }  /* * NOTE: dest must be an array for the following to work. */ #define PRNG_ADD_BITS(dest, dest_len, add, len, carry) \\ carry = 0; \\ PORT_Assert((dest_len) \u0026gt;= (len)); \\ { \\ int k1, k2; \\ for (k1 = dest_len - 1, k2 = len - 1; k2 \u0026gt;= 0; --k1, --k2) { \\ carry += dest[k1] + add[k2]; \\ dest[k1] = (PRUint8)carry; \\ carry \u0026gt;\u0026gt;= 8; \\ } \\ }  #define PRNG_ADD_BITS_AND_CARRY(dest, dest_len, add, len, carry) \\ PRNG_ADD_BITS(dest, dest_len, add, len, carry) \\ PRNG_ADD_CARRY_ONLY(dest, dest_len - len, carry) When the PRNG performs addition to update V it uses the macro PRNG_ADD_BITS_AND_CARRY, which first delegates to the macro PRNG_ADD_BITS to add the two summands without considering the final carry and then the macro PRNG_ADD_CARRY_ONLY to add the carry.\nIn this addition code it is clear that the carry should be added at the position preceding the original most-significant-byte of the shorter of the two summands. This fact was supposed to be represented by the index dest_len-len supplied as parameter to PRNG_ADD_CARRY_ONLY. Note that numbers are represented as sequences of bytes with byte number zero being the most-significant byte. The essence of the bug is that dest_len-len does not point to the correct position of the carry, which should have been added at position dest_len-len-1 instead.\n \nExample We note that 3 * 0x40 = 0xc0 under both proper and broken addition (the latter due to absence of carrying in this example). However, 3 * 0x95 = 0x01bf under proper unbounded addition resp. 0xbf under proper modulo addition. Yet, the result under broken addition is 0x01 + 0xbf = 0xc0.\nFinding the Bug with Testing The easiest way to find most types of bugs in PRNGs following NIST SP 800-90 is by testing the implementation with the official test vectors (seeds and outputs) provided in the standard. I found the bug after implementing these test vectors. Functional unit testing would probably have caught this particular bug as well. For PRNGs not following the NIST standard, defining corresponding test vectors is a good idea to avoid regressions during maintenance.\nStatistical tests such as NIST SP 800-22 or DIEHARDEST are not very useful for testing cryptographic PRNGs. They can be used for testing the entropy pool that is fed into the PRNG. But such tests will not fail as long as the internal state does not stay constant and output passes through a cryptographic primitive (such as SHA-256) before reaching the consumer.\nFormal Analysis Independ of my investigation, Vladimir Klebanov found this bug using Entroposcope, a static analysis tool created for finding implementation bugs in pseudo-random number generators.\nEntropy loss occurs when the number of possible output streams is less than the number of possible seeds. This is equivalent to the case when two different seeds produce the same output stream (also called a collision). Entroposcope is built on top of the bounded model checker CBMC, which in turn transforms the problem into a challenge for a SAT solver.\nConsidering the Hash_DRBG, the question whether Vc+1  = V + H(0x03 || Vc ) + C + c produces a collision and the DRBG loses entropy or not boils down to whether distinct 55-byte values x1, x2 exist, such that x1  + H(x1) = x2  + H(x2). Now, it is clear that this question cannot be answered without either knowing the output of H for each 55-byte input (which is infeasible) or some (unknown to us and certainly also to the tool) nontrivial mathematical argument on the nature of H in this context. In this regard, the Hash_DRBG differs from many other PRNGs that employ significantly simpler operations on the output of H before it makes its way to the PRNG caller.\nAs a consequence of this design, Entroposcope can not be used to prove absence of entropy loss in the Hash_DRBG. Nonetheless, Entroposcope can check collision-freedom of the PRNG under an idealised H and find bugs in the parts of the implementation that are not H. For this purpose we consider an idealised PRNG with H(b||V) = V and C = V0. This is the same kind of idealisation that helped Vladimir to uncover previously unknown bugs in OpenSSL and GnuPG. With the idealisation, on the first iteration (c = 0) updating the state becomes V1  = 3 * V0. Because 3 and 2440 are co-prime, V1 will not produce a collision if implemented properly.\nIndeed, given the idealised code, Entroposcope produced a counterexample to entropy preservation with two concrete seeds leading to the same output stream. Tracing these two executions makes it easy to pinpoint the cause of the collision in the addition code.\nThanks to Vladimir for finding this bug and helping to write this post.\n","date":"2017-08-31T00:00:00Z","image":"https://www.franziskuskiefer.de/p/cve-2017-5462-a-prng-issue/hero_hu3d03a01dcc18bc5be0e67db3d8d209a6_1186302_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.franziskuskiefer.de/p/cve-2017-5462-a-prng-issue/","title":"CVE-2017-5462 - A PRNG issue"},{"content":"After a couple of years using ghost I switched to the static page generator hugo. Hugo is easy to write and easy to publish. But more importantly it doesn\u0026rsquo;t offer the attack surface ghost does and doesn\u0026rsquo;t require external ressources like ghost does. It further decreases the amount of ressources used on the server.\n","date":"2017-08-29T00:00:00Z","permalink":"https://www.franziskuskiefer.de/p/new-website/","title":"New Website"},{"content":"AES-GCM is a NIST standardised authenticated encryption algorithm (FIPS 800-38D). Since its standardisation in 2008 its usage increased to a point where it is the prevalent encryption used with TLS. With 85% it is by far the most widely used cipher.\n Firefox 53 TLS cipher telemetry \nUnfortunately the AES-GCM implementation used in Firefox (provided by NSS) does not take advantage of full hardware acceleration; it uses a slower software-only implementation on Mac, Linux 32-bit, or any device that doesn\u0026rsquo;t have the AVX, PCLMUL, and AES-NI hardware instructions. Looking at these numbers about only 30% of Firefox users get full hardware acceleration.\nBefore jumping on the obvious issue of Firefox‚Äôs AES-GCM code being comparatively slow ‚Äì as well as not being resistant to side channel analysis ‚Äì I wanted to see what the actual impact on Firefox users is. Downloading a file on a mid-2015 MacBook Pro Retina with Firefox incurs CPU usage of 50% with 17% of Firefox\u0026rsquo;s CPU usage is in ssl3_AESGCM. In comparison, Chrome only creates 15% CPU usage with the same download. On a Windows laptop with an AMD C-70 (no AES-NI) Firefox CPU usage is 60% and the download speed is capped at 3.5MB/s. Chrome on the same machine needs 50% of the CPU and downloads with 10MB/s. This doesn\u0026rsquo;t seem to be only an academic issue: Particularly for battery-operated devices, the energy consumption difference would be noticeable.\nImproving GCM performance Speeding up the GCM multiplication function is the first obvious step to improve AES-GCM performance. A bug was opened on integration of the original AES-GCM code to provide an alternative to the textbook implementation of gcm_HashMult. This code is not only slow but has timing side channels. Here an excerpt from the binary multiplication algorithm.\nfor (ib = 1; ib \u0026lt; b_used; ib++) { b_i = *pb++; /* Inner product: Digits of a */ if (b_i) s_bmul_d_add(MP_DIGITS(a), a_used, b_i, MP_DIGITS(c) + ib); else MP_DIGIT(c, ib + a_used) = b_i; } We can improve on two fronts here. First NSS should use PCLMUL to speed up the ghash multiplication if possible. Second if PCLMUL is not available, NSS should use a fast constant-time implementation.\nBug 868948 has several attempts of speeding up the software implementation without introducing timing side-channels. Unfortunately the fastest code that was proposed uses table lookups and is therefore not constant-time. Thanks to Thomas Pornin I found a nicer way to implement the binary multiplication in a way that doesn\u0026rsquo;t leak any timing information and is still faster than any other code I\u0026rsquo;ve seen. (Check out Thomas' excellent write-up for details.)\nIf PCLMUL is available on the CPU, using it is of course the way to go. All modern compilers support intrinsics, which allows us to write \u0026ldquo;inline assembly\u0026rdquo; in C that runs on all platforms without having to write assembly. A hardware accelerated implementation of the ghash multiplication can be easily implemented with _mm_clmulepi64_si128.\nOn Mac and Linux the new 32-bit and 64-bit software ghash functions (faster and constant-time) are used on the respective platforms if PCLMUL or AVX is not available. Since Windows doesn\u0026rsquo;t support 128-bit integers (outside of registers) NSS falls back to the slower 32-bit ghash code (which is still more than 25% faster).\nImproving AES performance To speed up AES NSS requires hardware acceleration on Mac as well as on Linux 32-bit and any machine that doesn\u0026rsquo;t support AVX (or has it disabled). When NSS can\u0026rsquo;t use the specialised AES code it falls back to a table-based implementation that is again not constant-time (in addition to being slow). Implementing AES with intrinsics is a breeze.\nm = _mm_xor_si128(m, cx-\u0026gt;keySchedule[0]); for (i = 1; i \u0026lt; cx-\u0026gt;Nr; ++i) { m = _mm_aesenc_si128(m, cx-\u0026gt;keySchedule[i]); } m = _mm_aesenclast_si128(m, cx-\u0026gt;keySchedule[cx-\u0026gt;Nr]); _mm_storeu_si128((__m128i *)output, m); Key expansion is a little bit more involved (for 192 and 256 bit). But is written in about 100 lines as well.\nMac sees the biggest improvement here. Previously, only Windows and 64-bit Linux used AES-NI, and now all desktop x86 and x64 platforms use it when available.\nLooking at the numbers To measure the performance gain of the new AES-GCM code I encrypt a 479MB file with a 128-bit key (the most widely used key size for AES-GCM). Note that these numbers are supposed to show a trend and heavily depend on the used machine and system load at the time.\nLinux measurements are done on an Intel Core i7-4790, Windows measurements on a Surface Pro 2 with an Intel Core i5-4300U, and Mac (Core i7-4980HQ).\n Linux 64-bit encrypt   Linux 32-bit encrypt \nOn 64-bit Linux performance of any machine without AES, PCLMUL, or AVX instructions AES-GCM 128 is at least twice as fast now. If AES and PCLMUL is available, the new code only needs 33% of the time the old code took. The speed-up for 32-bit Linux is obviously more significant as it didn\u0026rsquo;t have any hardware accelerated code before. With full hardware acceleration the new code is more than 5 times faster than before. In the worst case, when PCLMUL is not available, the speed-up is still more than 50%.\nThe story is similar on Windows (though NSS had fast code for 32-bit there before).  Windows 64-bit encrypt \n Windows 32-bit encrypt \nPerformance improvements on Mac (64-bit only) range from 60% in the best case to 44% when AES-NI or PCLMUL is not available.  OS-X encrypt \nThe numbers in Firefox NSS 3.32 (Firefox 56) will ship with the new AES-GCM code. It will provide significantly reduced CPU usage for most TLS connections or higher download rates. NSS 3.32 is more intelligent in detecting the CPU\u0026rsquo;s capabilities and using hardware acceleration whenever possible. Assuming that all intrinsics and mathematical operations (other than division) are constant-time on the CPU, the new code doesn\u0026rsquo;t have any timing side-channels.\nOn the basic laptop with the AMD C-70 download rates increased from ~3MB/s to ~6MB/s. (Keep in mind that this is the software only 32-bit implementation.)\nThe most immediate effect can be seen on Mac. AES_Decrypt as part of a TLS connection with NSS 3.31 used 9% CPU while in NSS 3.32 it uses only 4%. To see general performance improvements we can look at the case where AVX is not available (which is the case for about 2/3 of the Firefox population). Assuming that at least AES-NI and PCLMUL is supported by the CPU we see the CPU usage drop from 15% to 3% (measured on Linux).\n","date":"2017-06-27T00:00:00Z","image":"https://www.franziskuskiefer.de/p/aes-gcm-speedup/linux64-encrypt_huda4d54ffc045a6df2c10e7f1ccf14ff2_16323_120x120_fill_box_smart1_3.png","permalink":"https://www.franziskuskiefer.de/p/aes-gcm-speedup/","title":"Aes Gcm Speedup"},{"content":"Writing constant time code is hard. We all know that. But I\u0026rsquo;m always amazed again on how difficult it is. In preparation for making NSS more constant time I looked into certain CPU instructions that are known to be not constant time. So I wrote a little thing to measure the time (CPU cycles) needed for division.\ndiv rcx ; eax is now a/b The CPU I\u0026rsquo;m using in this post is an Intel i7-4790 (haswell). Running the same measurements on other processors architectures will most likely yield different results. I\u0026rsquo;m describing two experiments I did. First, I look at bits in the divisor and how they influence the timing of the division. And then I look at the dividend and its influence.\nThe Divisor There are two interesting things we can look at here. The very small divisors as well as the pattern that we get in larger divisors.\n\u0026lt; 129  \nThis graph plots the number of cycles needed for the division of numbers \u0026lt; 130. It\u0026rsquo;s easy to see that the number of cycles needed is in general around 300. However, there are a couple of \u0026ldquo;outliers\u0026rdquo; that need significantly less.\n128 123 64 135 32 132 16 132 8 123 4 123 2 123 1 126 You might have spotted the pattern already. The CPU probably doesn\u0026rsquo;t want to do this expensive division and simply shifts the dividend to get the result. This trend continues later on but is more difficult to observe. (And there\u0026rsquo;s a more interesting pattern there.)\nThe larger pattern  \nThe graph shows a striking pattern and makes it obvious that division is not constant-time. Let\u0026rsquo;s try to understand what\u0026rsquo;s happening here.\nThe first part of the pattern can be explained by changing bit-lengths in the divisor. At 8191 and 16383 for example a streak of fast division ends. This is probably because the 8192 and 16384 require an additional bit each.\nHowever, I\u0026rsquo;m clueless on how to explain the rest of the pattern.\n(I\u0026rsquo;ll update this post when I figured out what\u0026rsquo;s going on.)\n","date":"2016-12-28T00:00:00Z","image":"https://www.franziskuskiefer.de/p/on-constant-time-division/plot_low-1_huce53492d5f2ce19360b675e9dc98bbf5_27543_120x120_fill_box_smart1_3.png","permalink":"https://www.franziskuskiefer.de/p/on-constant-time-division/","title":"On Constant Time Division"},{"content":"When I started working on NSS 7 months ago one of the tasks I was asked to do was to work through the related Coverity issues. This post summarises some learnings from this as we\u0026rsquo;ve since come a long way since over the last months.\nStatic analysis plays a crucial part in locating vulnerabilities and bugs during development. For NSS we currently use multiple static analysis tools. While scan-build as well as infer are great applications to find bugs, they require a lot of manual management. Features such as the incremental analysis of infer help with that though. Nonetheless, Coverity with its rich interface is the tool driving day to day analysis of NSS.\nWhen I started working on static analysis issues in NSS we only had Coverity scans for NSS releases in Firefox, which meant that we had to wait for six weeks or more to get feedback from the analyser on possible bugs. Now we have regular scans of the NSS tree as well as local scans with scan-build and infer.\nChallenges of a crypto library A big challenge when doing static analysis of a low-level (cryptographic) library is the high number of false positives. Errors like tainted value can very likely be totally benign code that shifts around some bits as often necessary for efficiently and securely implemented crypto algorithms. Many false positives also mean a lot of work without actually improving the code and an increased probability of missing an actual bug.\nDealing with technical debt A library as old as NSS naturally comes with a lot of technical debt, which creates a huge backlog of static analysis bugs. Mostly in code that hasn\u0026rsquo;t been of big interested to most developers so far.\n Coverity Analysis Overview \nIn our case tools such as Coverity come in especially handy as they allow for regular incremental scans with automatic updates on new bugs. We still have a long way to go to fix old bugs but the good news is that new bugs are rarely introduced and newly introduced bugs get fixed right away.\n Coverity density over time \nThe long-term goal is obviously to reduce the backlog of bugs to an acceptable level by either fixing or removing the code. But I think static analysis tools already significantly improved the quality of all new code.\n","date":"2016-05-25T00:00:00Z","image":"https://www.franziskuskiefer.de/p/nss-static-analysis/static-analysis_huc854eceb7630f71da830422ef5cde544_30572_120x120_fill_box_smart1_3.png","permalink":"https://www.franziskuskiefer.de/p/nss-static-analysis/","title":"NSS Static Analysis"},{"content":"~This extension doesn\u0026rsquo;t work from Firefox 57 on. I might update it when I find time.~\nEver wanted to view HTML pages directly from GitHub? Me too. Unfortunately the Raw button doesn\u0026rsquo;t render the HTML but only displays the source code. There are a bunch of Chrome extensions that add a button to open file from Github at rawgit directly, but none for Firefox. So I wrote one. It\u0026rsquo;s still an early version and more of a hack than a real extension, but it works (mostly).\nInstead of  without extension \nyou get now\n with extension \nDownload the source code at Github or download the signed extension.\n","date":"2016-01-02T00:00:00Z","permalink":"https://www.franziskuskiefer.de/p/rawgit-firefox-extension/","title":"RawGit Firefox Extension"},{"content":"Today I had to submit a paper through the Editorial Manager (used by Springer) for the first time. Needless to say that it\u0026rsquo;s not as easy as it sounds. Therefore here some helpful links for everyone having to do the same. I ended up putting the references in the .tex file as nothing else worked for me.\n http://www.bartneck.de/2010/09/30/submitting-your-latex-manuscript-to-editorial-manager-springer-elsevier/ http://drezha.me.uk/post/22719621060/submitting-a-springerlink-elsvier-journal-using  ","date":"2015-03-06T00:00:00Z","permalink":"https://www.franziskuskiefer.de/p/submitting-through-editorial-manager/","title":"Submitting through Editorial Manager"},{"content":"OpenPVN is an easy to set-up and use VPN solution that offer TUN/TAP support. In this tutorial I describe how to set-up an OpenVPN connection between a Ubuntu server and an Arch client.\nPreparations (Server) First we have to install OpenVPN on the server.\n# apt-get install openvpn To see whether TUN/TAP is enabled in the kernel we can check the kernel log grep tun /var/log/kern.log and load it if it doesn\u0026rsquo;t show up modprobe tun.\nCreating a PKI To use OpenVPN we need a PKI and certificates. Fortunately there is a script for that.\n# apt-get install easy-rsa First we create a folder to store our certificates in mkdir easy-rsa and get the default variables file cp /usr/share/easy-rsa/vars easy-rsa. The file is prefilled but one may want to change\nKEY_COUNTRY KEY_PROVINCE KEY_CITY KEY_ORG KEY_EMAIL KEY_OU All other standard parameteres should usually be fine but can be changed if desired. Now we change to /usr/share/easy-rsa and load the variables # source \u0026lt;PATH_TO_VARS\u0026gt;/vars and run ./build-ca. If there have been keys before one should run ./clean-all first.\nNow we can start creating keys and sign them. First we create the server key with\n# ./build-key-server my-test-server and aswer with yes two times. We do the same for a client key\n# ./build-key my-test-client To build Diffie-Hellman parameters we run ./build-dh (this can take some time). Eventually we create an HMAC key for our VPN and store it with the other keys\n# openvpn --genkey --secret /usr/share/easy-rsa/keys/ta.key Configuring OpenVPN (Server) Everything is set-up now to configure and run the OpenVPN server. First we copy the sample configuration file to the correct folder\n# cp /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz /etc/openvpn/ # gzip -d /etc/openvpn/server.conf.gz At least the following changes to server.conf should be made after copying keys, parameters and certificates.\nca /etc/openvpn/ca.crt cert /etc/openvpn/my-test-server.crt key /etc/openvpn/my-test-server.key dh /etc/openvpn/dh2048.pem tls-auth /etc/openvpn/ta.key 0 user nobody group nobody Starting OpenVPN (Server) The server can now be started with\nopenvpn /etc/openvpn/server.conf Configuring OpenVPN (Client) First we have to get key, certificate and parameters from the server to the client. Now we install OpenVPN on the client pacman -S openpvpn copy the sample-configuration file somewhere nice # cp /usr/share/openvpn/examples/client.conf /etc/openvpn/client.conf and modify at least the following\nremote test-server-ip 1194 ca /etc/openvpn/ca.crt cert /etc/openvpn/my-test-client.crt key /etc/openvpn/my-test-client.key dh /etc/openvpn/dh2048.pem tls-auth /etc/openvpn/ta.key 1 user nobody group nobody The test-server-ip has to be replaced with the server\u0026rsquo;s IP or URL. Now we can also start the client # openvpn /etc/openvpn/client.conf. The start-up should end with\nInitialization Sequence Completed ","date":"2014-10-12T00:00:00Z","permalink":"https://www.franziskuskiefer.de/p/openvpn-howto/","title":"OpenVPN HowTo"},{"content":"This post is work in progress but I never got around to finishing it. Sorry\nAfter a first failed attempt to install Snorby on an Arch Linux server (Snorby requires Ruby 1.9.x, Arch uses 2.x and I\u0026rsquo;m not willing to use the AUR version for this) I\u0026rsquo;m doing this on a Ubuntu 14.04 Server.\nSnort Before installing Snorby we have to install snort itself. This can be done with sudo apt-get install snort. Snort asks for a network address range to use for HOME_NET. Since I\u0026rsquo;m not sure what to use here (the network may change), I just use standard value. This can later be changed using snort config files.\nFor testing purposes I add a new rule file in /etc/snort/rules/ with a very basic rule that logs everything. You really shouldn\u0026rsquo;t do this in productive use, this will spam your snort output.\nfile: test.rules alert ip any any -\u0026gt; any any (msg:\u0026#34;Someone tried to access the server\u0026#34;; sid:100001; rev:1; priority:2;) To use the new rule file you have to include it in the snort config /etc/snort/snort.conf by adding a line include $RULE_PATH/test.rules.\nConfiguration In order to inspect outgoing traffic I had to add the -k none option to Snort in order to disable checksum tests for TCP connections (cf. serverfault). The option can be permanently added by adding it to PARAMS in /etc/default/snort.\nRules A common requirement for rules on a server is to inspect outgoing documents for suspicious content. Checking for example if a website contains a certain string can be done as follows:\nalert tcp any 80 -\u0026gt; any any (file_data; content:\u0026#34;Placeholder\u0026#34;; flow:to_client,established; msg:\u0026#34;Detected placeholderwebsite\u0026#34;; sid:1000002; rev:1; priority:2;) In order for this rule to work properly one has to make sure that snort.conf contains at least the following elements for http_inspect_server:\nxtended_response_inspection \\ inspect_gzip \\ normalize_utf \\ server_flow_depth 0 \\ normalize_javascript Snorby Before installing snorby I need to make sure that certain software is installed.\nPrerequesite The base system is a fresh Ubuntu 14.04 Server installation. Before installing Snorby we have to make sure that all requirements are installed. The Snorby website lists the following dependencies: git, ruby, ImageMagick and Wkhtmltopdf. But installing dependencies is not as easy as it sounds. I\u0026rsquo;m on a headless server and don\u0026rsquo;t want to install video drivers. So what to do with the strange Wkhtmltopdf package? And why the heck does a headless application need X? But luckily there is a ruby gem of wkhtmltopdf that does not need any X component (documentation of Snorby is really bad here). So we just use sudo gem install wkhtmltopdf and we are good (ignore the errors during installation). We also have to install ruby-dev and make on Ubuntu. Further we need mysql-server installed. To get rails and bundler we have to install them with sudo gem install bundler and sudo gem install rails.\nInstalling Snorby Now we need to get snorby sources\ngit clone https://github.com/Snorby/snorby After changing to the cd snorby directory we can install it using bundle install.\nNow we have to configure snorby to be able to read events from the database. To do so we copy database.yml.example in the config folder to database.yml and change the database configuration to access MySQL. Further we copy snorby_config.yml.example to snorby_config.yml and check that wkhtmltopdf and domain are correct in the production section. It seems there are more dependencies needed (in particular nokogiri needs more). So we have to install libxml2-dev, libxslt-dev,  libmysqlclient-dev, g++.\nNow we should be able to run\nbundle exec rake snorby:setup to set-up snorby and start it with\nbundle exec rails server -e production Instaling Barnyard2 To get the snort output into our Snorby interface we use Barnyard2. Since there is no package for Ubuntu in the official repositories we have to build Barnyard2 from source.\ngit clone https://github.com/firnsy/barnyard2 To build Barnyard2 we need some developement tools\nsudo apt-get install build-essential libtool autoconf libpcap-dev libmysqld-dev After changing to the Barnyard2 directory cd barnyard2 we run ./autogen.sh, configure it for MySQL ./configure --with-mysql --with-mysql-libraries=/usr/lib/x86_64-linux-gnu/ (the additional library and include path are necessary on Ubuntu to find MySQL) run make. I only enable MySQL here, but other outpus are possible. To eventually install Barnyard to we use sudo make install.\nAfter installing Barnyard2 it needs configuration. First I copy the example config file sudo cp etc/barnyard2.conf /etc/ before modifying it to run as a daemon and write to the database\nconfig daemon config hostname: localhost config interface: eth0 output database: log, mysql, user=root password=root dbname=snort host=localhost config logdir: /var/log/barnyard2/ config waldo_file: /var/log/barnyard2/barnyard2.waldo Database Setup We have to set up the Barnyard2 database. We create a new database create database snort;, get the Barnyard2 schema\nwget https://raw.github.com/firnsy/barnyard2/master/schemas/create_mysql and install it to our new database mysql -u \u0026lt;user\u0026gt; -p snort \u0026lt; create_mysql.\nTroubleshooting I ran into the problem that snort had no sid-msg.map. This can be created with\n# /usr/share/oinkmaster/create-sidmap.pl rules/ \u0026gt; sid-msg.map in /etc/snort. I ran into some further problems and had to create the waldo file manually, i.e.\nsudo touch /var/log/barnyard2/barnyard2.waldo sudo chown snort:snort /var/log/barnyard2/barnyard2.waldo This still throws a warning that the waldo file is corrupt, but Barnyard2 is at least running. I got a lot of warnings of the form\nWARNING: Can't extract timestamp extension from '..'using base '' from old/corrupted snort log files. So I removed all logs from `/var/log/snort/`. Note that this warning is also shown when the snort log is empty!  To start Barnyard2 now we use\nsudo /usr/local/bin/barnyard2 -c /etc/barnyard2.conf -d /var/log/snort/ -f snort.out where the first parameter sets the config file to use, the second tells barynard2 in which folder to look for snort output files and the last one gives the base-name of snort output in that folder.\nTesting the setup To test if Snorby is actually working I install and start Apache. This is not necessary since my snort rule from above is logging everything, but you may want to do this anyway to test some real rules. The Snorby web interface is located at http://\u0026lt;server ip\u0026gt;:3000/. The default credentials are Username: snorby@snorby.org, Password: snorby.\n","date":"2014-10-05T00:00:00Z","permalink":"https://www.franziskuskiefer.de/p/snort-barnyard2-snorby/","title":"Snort, Barnyard2 \u0026 Snorby"},{"content":"Over the last year I was battling a strange error of reverse synctex search with evince and several latex editors. Everything works perfect with synctex unless I want to do a reverse search (click in the pdf docutment and get the according tex position) on the first page. Instead of getting the correct position my latex editor always opens the file pgflibraryfadings.code.tex. While I finally found the cause of the problem, I have no idea how to solve it. The problem seems to stem from the inclusion of the shadows tikz library. Without the package included everything works flawless. I filed a bug report at sourceforge.\n","date":"2014-09-01T00:00:00Z","permalink":"https://www.franziskuskiefer.de/p/the-curious-case-of-pgflibraryfadings/","title":"The curious case of pgflibraryfadings"},{"content":"Another day in latex wonderland \u0026hellip; Today I was writing an equation in an aligned environment using sum and those fancy things. Unfortunately aligned is a display math environment such that the limits of sum are displayed above and below, which was really not suitable in my case. So how do I display inline-math style in a display math environment?\nLet\u0026rsquo;s say we have an equation environment with an equation\n\\begin{equation*} \\sum_{i=0}^{n} x^i \\end{equation*} To display the sum as inline math we can simply use \\textstyle.\n\\begin{equation*} {\\textstyle \\sum_{i=0}^{n} 2^i} \\prod_{i=0}^{n} i^2 \\end{equation*} Note that the prod is display math again.\n","date":"2014-08-17T00:00:00Z","image":"https://www.franziskuskiefer.de/p/display-inline-math/hero_hu3d03a01dcc18bc5be0e67db3d8d209a6_279506_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.franziskuskiefer.de/p/display-inline-math/","title":"Display \u0026 Inline Math"}]